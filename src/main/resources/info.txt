redis特性
    速度快  10W OPS  读写 存储在内存之中 主要原因 线程模式：单线程
    持久化 数据保存在内存之中，但将数据异步的保存在磁盘上
    多种数据结构 string hash linkList set ,sorted sets;bitMaps 位图  ；HyperLogLog：超小内存唯一值技术（可能存在误差率）；GEO地理位置定位
    支持多种语言
    功能丰富 发布订阅 LUA脚本  简单事务 pipeline
    简单 23000行代码，不依赖外部库 ，单线程线程模型
    主从复制
    高可用，分布式
使用场景
    缓存系统

    计数器
    消息队列
    排行榜
    社交网络
    实时系统
redis 的安装与部署
    获取 tar.gz的包  wget http://download.redis.io/releases/redis-3.0.7.tar.gz
    tar -zxvf xxxx.tar.gz
    ln -s redis-3.0.7 redis 建立软连接
    make  在src目录中出现 如下6个文件
        redis-server  redis 服务器
        redis-cli redis  命令行客户端
        redis-benchmark  基准测试，测试性能
        redis-check-aof  对aof文件进行修复
        redis-check-dump RDB文件修复工具
        redis-sentinel  启动 redis-sentinel 节点，高可用
    make install 会将上述6个拷贝到usr/local/bin目录下

    三种启动方法
        最简启动  执行redis-server  命令
        动态参数启动   6379 redis-server --port 6380
        配置文件启动(推荐)
    redis 客户端连接
        redis-cli -h 127.0.0.1 -p 6379
        test:  ping     return  pang
    redis 返回值
        ping -- pang
        错误回复
        整数回复
        字符串回复
        多行字符串回复
redis 常用配置
    daemonize 是否为守护线程 yes/no(建议yes)
    port  端口
    logfile 日志名
    dir  redis工作目录 日志，和持久化文件  6379-》merz 意大利女歌手的名字
    查看配置文件时，将一些#，和一些空格去掉 cat redis.conf | grep -v "#" | grep -v "^$" > redis-6380.conf
    建议使用redis-server redis.conf 这样的配置文件的方式启动程序

redisAPI的使用和理解
    通用命令
        keys *   热备从节点  scan   O(n)
            keys he*
            keys he[h-j]*
            keys ph?
            等等通配符
        FLUSHALL 删除所有的数据
        dbsize  算出key的总数  O(1)
        exists key  O(1)
        del key  O(1)
        expire key seconds 过期时间  O(1)
        type key  O(1)
        ttl key 查看剩余过期时间  O(1)
        persist key 去掉key的过期时间  O(1)
        type key  返回key的类型  string hash list set zset none  O(1)
    字符串类型
    哈希
    列表
    集合
    有序集合

    单线程
        所有命令都是串行的，单线程的，一个瞬间，只会执行一条命令
        为什么单线程还这么块？
        1.纯内存*
        2.非阻塞IP
        3.避免了线程切换和竞争

        拒绝长命令 keys *，flushall 等，会使线程阻塞

    字符串
        结构和命令
            key          value 不能大于512MB
            常用于 缓存 计数器  分布式锁 等等
            incr 自增1 decr自建1 incrby 自增n decrby 自减1
            实现 网站用户访问量
            incr userid:pageview

            缓存视频的基本信息

            多客户端并发获取自增id

            set key value  覆盖
            setnx key value  不存在，再能设置，新增
            set key value xx 存在，才能设这，更新

            mget key1 key2
            mset key1 value1 key2 value2

            getset key newvalue 设置新值，返回老值
            append key value 对某一个key的value进行追加
            strlen key 获取字符串长度，注意中文

            incrbyfloat key 3.5 自增
            getrange key 0 3 获取字符串中的某些值
            setrange key 0 3
        内部编码


        哈希
            特点
            重要api
            hget hget key field
            hset key field value
            hdel key field
            hexists key field
            hlen key  field的数量
            hmget key field1 field2
            hmset key field1 value1 field2 value2
            hgetall key 返回该key的所有的field 和 value   尽量不要用，比较危险
            hval key 返回该key的所有的 value
            hkeys key 返回该key所有的 field

            hsetnx key field value 如果已经存在，则失败
            hincrby key field intCounter
            hincrbyfloat key field floatCounter

            实战
            页面访问量
            hincrby user:1:info pageview count
            缓存基本信息

            hash vs string

        列表
            特点
            列表有序的，可以重复的 ，可以从左右插入弹出的

            重要API
            rpush key value1 value2 ...
            lpush key value1 value2 ...

            linsert key before|after value newValue  重复的呢？？
            lpop key 弹出元素
            rpop key 右边弹出元素

            lrem key count value
            count > 0 从左到右 ，从列表中删除count个value相等的值；(因为存在相同的元素)
            count < 0 从右到左 ，从列表中删除count个value相等的值；(因为存在相同的元素)
            count = 0 删除所有的与value相等的值

            ltrim key start end
            lrange key start end (包含start end)
            lindex key index
            llen
            lset key index newValue
            blpop key timeout  timeout = 0永远不阻塞
            brpop
            LPUSH + LPOP = Stack
            LPUSH + RPOP = Queue
            LPUSH + LTRIM = Capped Collection
            LPUSH + BRPOP = Message Queue

            实战
            微博 timeLine

        集合
            sadd key element 如果存在则失败

        有序集合
Redis 客户端 Jedis
    TCP协议

瑞士军刀
    慢查询
        生命周期
            发送命令 - 排队 - 执行命令 - 返回结果
            慢查询发生在第三阶段

        两个配置
            slowlog-max-len = 128
            慢查询 有自己的队列，长度是固定的，保存在内存中，一开始的可能被清空
            slowlog-log-slower-than (us)  = 10000
            如果想让所有的都进入慢查询 则设置为0
            不记录 <0
            可以写入配置文件
            可以动态配置
            config set slowlog-max-len 1000
        三个命令
            slowlog get[n] n条慢查询
            slowlog len 长度
            slowlog reset 清空
        运维经验
            1 slowlog-log-slower-than不要过大，默认10ms，通常设置1ms
            2 slowlog-max-len 不要过小 一般1000左右
            3 理解命令生命周期
            4 定期持久化慢查询（how to do？？）
pipeline 功能  流水线
    什么是流水线
        将多次命令打包，一次传出，一次返回
    客户端的实现

    与原生操作对比
    使用建议
        注意pipeline 的携带数量
        pipleline只能作用在一个节点上
        M操作与pipleline的区别
发布订阅
    角色
        发布者
        订阅者
        频道
    模型
    API
        publish channel message
        subscribe [channel]
        unsubscribe [channel]
        psubscribe [pattern...]

Bitmap
    位图
    相关命令
    setbit key offset value
    独立用户统计


持久化
    什么是持久化
        数据保存在内存中，断电后，数据丢失，于是将数据异步的更新保存到磁盘之中
    持久化的实现方式
        快照
            mysql dump 和  redis 的RDB 使用的是快照
        日志
            所有的操作存放到日志中
            mysql Binlog; Hbase Hlog;  Redis AOF   日志
    RDB
        什么是RDB
            二进制
        触发机制-3中方式
            save 同步
                直接执行save命令，直接生成RDB文件
                同步命令 ，造成其他命令的阻塞
                新文件，会替换老文件
                会阻塞，但是不会额外消耗内存
            bgsave 异步
                client 执行bgsave 命令，redis 会执行一个fork()函数，主进程会生成一个子进程，去生成RDB
                fork（）是同步操作，虽然很短
                不会阻塞，但是会执行fork操作，会消耗额外内存
            自动
                配置
                save 900 1
                save 300 10
                dbfilename dump.rdb(默认)
                stop-writes-on-bgsave-error yes 出现问题，停止写入
                rdbcompression yes 是否采用压缩的格式
                rdbchecksum yes 是否检验？？

                推荐配置
                dbfilename dump-${port}.rdb
                stop-writes-on-bgsave-error yes
                rdbcompression yes
                rdbchecksum yes

        触发机制-不容忽略的方式  一下会出发生成rdb文件
            全量复制 主从复制的时候
            debug reload
            shutdown
    AOF
        RDB现存问题
            耗时耗性能O(n)
            fork 消耗内存，copy-on-write策略
            硬盘IO消耗
            不可控，容易丢失数据  （自动save的时候）
        什么是AOF
            AOF文件，记录着所有的操作
        3种策略
            always
                写命令刷新都缓冲区中,每条命令都都会从缓冲区写入到硬盘中
                不丢数据，但硬盘开销大
            everysec （默认）推荐这个
                写命令刷新都缓冲区中,每秒都会从缓冲区写入到硬盘中 ，
                有可能会丢失一秒的数据
                保护一下磁盘
            no
                由操作系统决定，什么时候刷入，什么时候不刷
                不用管
                不可控，一般不会用

        AOF重写
            会将多条命令合并，过期的去除，以减少数据量，这样日志不会无限的增长下去
            可以加快恢复速度

            两种实现方式
                bgrewriteaof 命令
                    fork出子进程，执行重写，重写其实是将现在内存中数据，进行统计，而不是真的去统计历史日志
                AOF重写配置
                    auto-aof-rewrite-min-size 需要到达多大进行重写
                    auto-aof-rewrite-percentage aof 的增长率

                    appendonly yes
                    appendfilename "appendonly-${port}.aof"
                    appendfsync = everysec
                    dir
                    no-appendfsync-on-rewrite yes
                    auto-aof-rewrite-min-size 64mb
                    auto-aof-rewrite-percentage 100

如何选择两者
    RDB&AOF
    aof优先等级高
    rdb 体积小
    rdb回复快
    RDB重量级

    RDB
    “关”
    集中管理，比如按天备份

    aof
    开

    最佳策略
    小分片
    max_memory

运维常见问题
    fork操作
        如何查看fork操作时间
        info:latest_fork_usec 微秒
        改善fork
        更好的硬件设备或虚拟化技术
        控制Redis的最大使用内存 maxmemory  内存越大，fork时间越大
        合理配置Linux内存分配策略 vm.overcommit_memory=1 geiredis分配无上限
        降低fork频率 房款aof重写的出发机制，不需要全量复制

        子进程开销
        cpu
            文件生成，cpu密集型操作
            优化，不错cpu绑定，不和cpu密集型的部署在一起
        memory
            fork内存开销
        硬盘的消耗


    进程外开销
    AOF追加阻塞

    单机多实例部署

redis复制的原理与优化
    什么是主从复制
        机器故障（高可用）
        容量平静（分布式）
        qps瓶颈
    复制配置
        两种方式
        slaveof 命令
        在A上执行 slaveof B A就成为了B的子节点

        取消复制
        slaveof no one 但是数据不会删除
        主给从同步数据的时候，会先清除从节点数据

        配置s
        slaveof ip port
        slave-read-only yes

        info reapplication 查看分片信息

    全量复制和部分复制
    故障处理
    常见的运维问题
        读写分离

        主从不一致
        避免全量复制
        避免复制风暴
redis Sentinel （哨兵）…………6的飞起
    主从复制高可用？架构说明

    sentinel 会对各个redis节点进行监控
    客户端这个时候从sentinel获取数据，sentinel来维护谁是master谁是slave
    当master宕机了，会执行如下的操作
    1.多个sentinel发现并确定master有问题
    2.选举一个sentinel作为领导
    3.选举出一个slave作为master
    4.通知其余的slave成为新的master的slave
    5.同事客户端主从的变化
    6.等待老的master复活成为新的master的slave

    sentinel还可以同事监控多套master-slave

    安装和配置
    1.配置开启主从节点
        redis主节点
        如：配置redis-7000.conf 配置文件
        port 7000
        daemonize yes
        pidfile /var/run redis-7000.pid
        logfile "7000.log"
        dir "...../redis/data"

        从节点
        slave1  其实配置是一样的，不同的是需要配置slave of 属性
        port 7001
        daemonize yes
        pidfile /var/run redis-7001.pid
        logfile "7001.log"
        dir "...../redis/data"
        slaveof 127.0.0.1 7000

        slave2  其实配置是一样的，不同的是需要配置slave of 属性
        port 7002
        daemonize yes
        pidfile /var/run redis-7002.pid
        logfile "7002.log"
        dir "...../redis/data"
        slaveof 127.0.0.1 7000

    2.配置开启sentinel监控主节点（sentinel可以理解成为特殊的redis）
        sentinel 也是分布式的，真正做到sentinel也是高可用的
        sentinel 的主要配置
        port ${port}
        daemonize yes  以守护进程的方式启动
        dir "....../redis/data"
        logfile "$sentinel-${port}.log"
        sentinel monitor mymaster 127.0.0.1 7000 2  mymaster是主节点的名字   2是超过2个sentinel认为master是有问题的
            sentinel moniter <masterName> <ip> <port> <quorum(法定人数)>
        sentinel down-after-milliseconds mymaster 30000     (ms) 超过多久没有回应，认为是有问题的
        sentinel parallel-syncs mymaster 1 复制 ？？ 每次只能复制一个？没太懂
        sentinel failver-timeout mymaster 180000

        这里的mymaster，是干什么用的呢，就是一个名字；因为sentinel可以同时见识多套：redis的集群，mymaster就是用来区分这些集群的
        在配置sentinel的时候，我们只配置主节点的信息，却没有配置从节点的信息；以为sentinel 会在主节点上执行一个类似info reapplication的命令，就可以获取到从节点的信息了

        一个查看节点信息的命令  ：redis-cli -p7000 info replication

        将注释和空行都去掉： cat sentinel.conf | grep -v "#" | grep -v "^$"
    3.实际应该部署在多台设备上
    4.详细配置节点
        一个查看节点信息的命令  ：redis-cli -p7000 info replication
        将注释和空行都去掉： cat sentinel.conf | grep -v "#" | grep -v "^$"

        启动sentinel命令
        redis-sentinel redis-sentinel.conf

        连接sentinel：redis-cli -p 26379
        启动之后，sentinel会重写配置文件，比如，加入slave的相关信息

java客户端连接
    步骤
    1.首先要获取到sentinel的集合，因为我们不知道到底哪个是可用的；
    2.通过集合+master-name 去便利集合，获取一个可用的sentinel节点；
    3.在sentinel节点上 执行get-master-addr-by-name 来获取 master节点的地址和端口
    4.对master节点执行一次role或者role replication 来确定一些这孙子到底是不是阵中的master节点
    5.那么，如果master发生了故障，客户端是怎么知道的呢？？？
        这里用到了redis的发布订阅的功能呢， 客户端去订阅sentinel的某一个频道，当master发生变化的时候
        sentinel就会pubulish一条信息，这样客户端就能兼听得到，然后重新连接新的客户端就是了；这样，客户端不用每次都去获取master信息

    故障转移，其实是需要时间的，大约30秒之后，才会发现master down掉了,然后开始故障转移

    从日志看出
    当7000被杀掉的时候，7002一直处于与master失联的一个状态，一直请求失败，但是很快，他接受到了一条请求，让他成为新的master
    然后，有一个配置重启的过程，故障转移成功，7001开始从7001上面复制数据
    那sentinel发生了什么呢？
    首先，其中一个sentinel节点他认为7000发生了故障，然后确定了客观下线（也就是说，有超过一定数量的sentinel节点，也认为7000出现了故障）
    这个节点希望成为一个领导者
    然后其他的sentinel节点给他投了票
    于是他成了sentinel的master
    他开始选择一个合适的slave节点，然后发送了slaveof-noone命令给了这个slave节点，然后开始等待slave晋升，同事发送请求给其他的slave
    让他们从新的master上进行数据的复制
    他还会给7000一个odown 的一个表示，目的上当7000再次上线的时候，他会让7000区新的master上进行数据的复制
    整个过程转换成功
    其他的sentinel节点，没什么任务，他们主要是负责发现问题，然后选举一个master，具体的事情由master去做就是了

setinel的三个定时任务
    为了保证这个过程
    sentisentinel内部有三个定时任务来保证完成
    1.每10秒每个sentinel会对master和slave 做info操作，这样做的目的是：
        1.发现新的slave节点，我们在配置sentinel的时候，并没有配置slave的信息，但是sentinel启动之后，conf文件会被重写
            出现了slava的信息，说明sentinel会对master和slave做info操作
        2.发现主从关系
    2.没过两秒钟，每个sentinel会通过master上的一个频道（_sentinel_:hello）进行一个消息的发布和订阅
        1.相互交换对节点的看法，和自身的信息，从而达成一致；这也就是为什么当我们加入一个sentinel节点的时候，其他的sentinel
            节点会立刻感知出来，就是因为加入了这个频道来获取彼此的信息
    3.每一秒，每个sentinel节点会对其他的sentinel和redis执行一个ping的操作，相当于进行一个心跳检测

主管下线和客观下线
    sentinel monitor mymaster 127.0.0.1 7000 2  mymaster
        sentinel moniter <masterName> <ip> <port> <quorum(法定人数)>
    sentinel down-after-milliseconds mymaster 30000     (ms) 这里就是，用于做主管下线的判断依据
    主观下线：每个sentinel节点对于redis节点失败的“偏见”
    客观下线：说有sentinel节点对于redis节点失败“达成共识”（超过quorum）
    sentinel会通过  sentinel is-master-down-by-addr 命令来交流对下线的看法
    quorum 建议  节点数/2 + 一 建议sentinel节点的数量是一个奇数
领导的选举
    只有一个sentinel节点来完成故障转移
    选举：通过sentinel is-master-down-by-addr 来都希望自己成为领导者
    步骤如下：
    1.每个做主管下线的sentinel 节点会想其他节点发送命令，要求及自己成为领导者
    2.收到命令的sentinel节点如果没有同意过其他的节点，就会同意，否则拒绝
    3.如果sentinel 节点发现自己的票数超过一半，而且超过quorum，那么他将成为领导者
    4.经过了这个过程，其实会出现多个领导者，那么，一个时间后，会进行重新的选举，直到出现唯一的领导者

故障转移（sentinel的领导者已经产生）
    1.从slave节点中选出一个“合适的”节点作为新的master节点
        什么是合适的呢？
         1 选举slave-prioprity比较高的slave，如果不存在，则继续（可以手工配置优先级）
         2 选择复制偏移量最大的slave节点，也就是复制最完整的一个节点，如果不存在，则继续
         3 选择runId 最小的节点
    2.对上述的节点执行slaveof no one 命令其成为master节点
    3.向剩余的slave节点发送命令，让他们成为新的master的slave节点，复制规则和parallel-syncs参数有关。
        有什么关系呢？
        当新的master产生的时候，众多slave 会想master发送复制请求，当节点众多的时候，会加大对master的负担，
        parallel-syncs 的参数就是说一时间，允许几个slava去发送请求，正前面的执行完毕之后，后面的再一次执行
        从而大到一个保护的作用；不过如果对于一些特殊的情况，比如读写分离，需要快的进行主从复制的情况下，这个值
        还是可以适当的调试大一些的；


常见运维问题
    1.节点运维     节点上线下线的操作
        机器下线：例如过保情况，机器性能不足等，需要更换机器，机器本身故障，服务器不稳定，会使上面的节点下线
        节点下线
            主节点
                sentinel failover masterName  手动故障转移
            从节点
                是临时下线，还是永久下线，要考虑读写分离的情况
            sentinel节点

        节点上线
            主节点
                sentinel failover 进行替换
            从节点
                slaveof即可，sentinel节点可以感知
            sentinel节点：
                参考其他sentinel节点启动即可，加入到那个频道中，就会自动感知

高可用读写分离




Redis Cluster
    呼唤集群（为什么）
        为什么需要集群这样的功能
        并发量：10WQPS/每秒（官方）
        容量：
        网络流量
        以上的限制都会使得单机无法满足
    数据分布
        分区方式
            顺序分区
                有100分分区，三个节点，每个上面33份数据，叫做顺序分布
                特点：数据分散容易倾斜；键值业务相关；可顺序访问；支持批量操作
                典型产品：BigTable；HBase
            hash分区
                将每一个节点做一个hash函数，来计算放置在那个节点上
                特点：数据分散度高；键值分布于业务无关；无法顺序访问，支持批量操作
                典型产品：一致性哈希Memcache
                            redis cluster
                            其他缓存产品
        hash算法
            取余算法
                这样的算法，分散度比较好，比如，有3个节点，就对三进行取余，有四个节点，就对4进行取余， 这样就能知道数据在哪个节点上分布
                不过这样做，当有节点上线或者下线的时候，数据就要重新迁移，80%左右，这样是灾难性的；
                在数据较小的情况下，建议翻倍增量，比如原来有3个节点，要增加，就增加到6个，这样的数据迁移会小一些，大约50%左右
            一致性哈希 ，数分布在一个32位的空间内，0-2的31次方，可以看做是一个圆环（token环），然后顺时针寻址；详情去网上搜索，有点复杂
                这个算法在memcache上使用的比较广泛

    搭建集群
    集群伸缩
    客户端路由
    集群原理
    开发运维常见的问题
    集群与单机的对比



    2.高可用版本的读写分离








